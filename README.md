# Building around Language Models
## N-grams
- Build and train different n-gram models.

## Similar Text generator
- A text generator that can write in the style similar to the trained data.<br>
- Models are based on transformer architecture and built with Python and Pytorch <br>
- Experimenting on different attention score calculation methods like additive and local attention.

## OpenAI_API
- Explore and Experiment on Openai API, including usage of different models such as GPT, DALL, TTS and Whisper, and prompt engineering.

## Tokenization
- Currently trying to Buildi a tokenizer from scratch.

## Mamba
- Exploring the newly published language model architecture.
